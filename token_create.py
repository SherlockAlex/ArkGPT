from tokenizer import Tokenizer

tokener = Tokenizer(mode="char",encoding="utf-16").load("./chinese.json")